# Large Scale Requirements Engineering System - Module 1

A production-ready system for requirements intake, preprocessing, and SRS generation at scale. This system implements the complete Module 1 pipeline as specified in your FYP project.

## üèóÔ∏è System Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Input Layer   ‚îÇ    ‚îÇ  Processing      ‚îÇ    ‚îÇ  Output Layer   ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ  Layer           ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ Text Files    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ Whisper        ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ SRS Documents ‚îÇ
‚îÇ ‚Ä¢ Audio Files   ‚îÇ    ‚îÇ ‚Ä¢ Flan-T5        ‚îÇ    ‚îÇ ‚Ä¢ JSON Reports  ‚îÇ
‚îÇ ‚Ä¢ CSV/JSON      ‚îÇ    ‚îÇ ‚Ä¢ spaCy          ‚îÇ    ‚îÇ ‚Ä¢ HTML Reports  ‚îÇ
‚îÇ ‚Ä¢ Direct Input  ‚îÇ    ‚îÇ ‚Ä¢ Batch Processor‚îÇ    ‚îÇ ‚Ä¢ Database      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Project Structure

```
Module 1/
‚îú‚îÄ‚îÄ requirements.txt              # Dependencies
‚îú‚îÄ‚îÄ main_orchestrator.py         # Main entry point
‚îú‚îÄ‚îÄ module1_large_scale.py       # Core processing engine
‚îú‚îÄ‚îÄ batch_processor.py           # Batch processing system
‚îú‚îÄ‚îÄ srs_generator.py             # IEEE 830 SRS generator
‚îú‚îÄ‚îÄ data_manager.py              # Data management system
‚îú‚îÄ‚îÄ data/                        # Data directories
‚îÇ   ‚îú‚îÄ‚îÄ input/                   # Input files
‚îÇ   ‚îú‚îÄ‚îÄ output/                  # Output files
‚îÇ   ‚îú‚îÄ‚îÄ temp/                    # Temporary files
‚îÇ   ‚îî‚îÄ‚îÄ exports/                 # Export files
‚îú‚îÄ‚îÄ models/                      # Model storage
‚îî‚îÄ‚îÄ requirements.db              # SQLite database
```

## üöÄ Quick Start

### 1. Installation

```bash
# Create virtual environment
python -m venv requirements_env
requirements_env\Scripts\activate  # Windows
# source requirements_env/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Download spaCy model
python -m spacy download en_core_web_sm
```

### 2. Basic Usage

**Process Single Requirement:**
```bash
python main_orchestrator.py --mode single --input_text "The system must provide real-time stock updates"
```

**Process Batch of Files:**
```bash
python main_orchestrator.py --mode batch --input_dir data/input --output_dir data/output
```

**Generate SRS Document:**
```bash
python main_orchestrator.py --mode srs --results_file processed_results.json
```

## üîß System Components

### 1. **RequirementsProcessor** (`module1_large_scale.py`)
- **Input Collection**: Handles text and audio inputs
- **Audio Transcription**: Uses Whisper for speech-to-text
- **Text Preprocessing**: spaCy-based NLP processing
- **Ambiguity Detection**: Identifies unclear terms and phrases
- **Field Extraction**: Uses Flan-T5 for structured extraction

### 2. **BatchProcessor** (`batch_processor.py`)
- **Batch Processing**: Handles multiple files efficiently
- **Format Support**: CSV, JSON, text, audio files
- **Progress Tracking**: Real-time processing status
- **Error Handling**: Robust error management

### 3. **SRSGenerator** (`srs_generator.py`)
- **IEEE 830 Compliance**: Generates initial SRS sections (Module 1 scope)
- **Multiple Formats**: JSON, HTML output
- **Section Generation**: Introduction and Overall Description only
- **Template System**: Customizable SRS templates

### 4. **DataManager** (`data_manager.py`)
- **Database Storage**: SQLite for metadata and results
- **Data Import/Export**: Multiple format support
- **Version Control**: Track processing history
- **Query System**: Advanced data retrieval

## üìä Processing Pipeline

### Stage 1: Input Collection
```
Text Input ‚îÄ‚îÄ‚îê
             ‚îú‚îÄ‚îÄ‚ñ∫ RequirementsProcessor
Audio Input ‚îÄ‚îò
```

### Stage 2: Processing
```
Transcription ‚îÄ‚îÄ‚ñ∫ Preprocessing ‚îÄ‚îÄ‚ñ∫ Ambiguity Detection ‚îÄ‚îÄ‚ñ∫ Field Extraction
     ‚îÇ                ‚îÇ                    ‚îÇ                    ‚îÇ
   Whisper         spaCy              Pattern Matching      Flan-T5
```

### Stage 3: Output Generation
```
Processed Data ‚îÄ‚îÄ‚ñ∫ SRS Generation ‚îÄ‚îÄ‚ñ∫ Document Export
                      ‚îÇ
                 IEEE 830 Format
```

## üéØ Key Features

### **Large Scale Processing**
- **Batch Processing**: Handle thousands of requirements
- **Parallel Processing**: Multi-threaded execution
- **Memory Optimization**: Efficient resource usage
- **Progress Tracking**: Real-time status updates

### **Advanced Ambiguity Detection**
- **Pattern Matching**: 7 categories of ambiguous terms
- **Context Analysis**: Surrounding text analysis
- **Suggestions**: Automated clarification prompts
- **Confidence Scoring**: Ambiguity likelihood assessment

### **IEEE 830 Compliance (Module 1 Scope)**
- **Initial SRS Structure**: Introduction and Overall Description sections only
- **Purpose and Scope**: System overview and context
- **Product Functions**: High-level functionality identification
- **User Characteristics**: Stakeholder identification
- **Constraints and Dependencies**: System limitations and requirements

### **Data Management**
- **Multiple Formats**: JSON, CSV, Parquet, SQLite
- **Incremental Processing**: Resume interrupted batches
- **Data Validation**: Input/output validation
- **Export Capabilities**: Flexible data export

## üìà Performance Characteristics

### **Processing Speed**
- **Text Processing**: ~100-500 requirements/minute
- **Audio Processing**: ~10-50 files/minute (depending on length)
- **Batch Size**: Configurable (default: 10 items/batch)
- **Memory Usage**: ~2-4GB for full model loading

### **Scalability**
- **Horizontal Scaling**: Multi-processor support
- **Vertical Scaling**: Memory and CPU optimization
- **Storage Scaling**: Database and file system support
- **Network Scaling**: Distributed processing ready

## üîç Usage Examples

### **Example 1: Process Stock Prediction Requirements**

```bash
# Create input directory
mkdir -p data/input

# Add your requirements files
echo "The system must predict stock prices using machine learning algorithms" > data/input/req1.txt
echo "Users should be able to set up personalized alerts for price changes" > data/input/req2.txt

# Process batch
python main_orchestrator.py --mode batch --input_dir data/input

# Generate SRS
python main_orchestrator.py --mode srs --project_title "Stock Prediction System"
```

### **Example 2: Process Audio Requirements**

```bash
# Process single audio file
python main_orchestrator.py --mode single --input_file requirements_audio.wav

# Process directory of audio files
python main_orchestrator.py --mode batch --input_dir audio_requirements/ --file_patterns .wav .mp3
```

### **Example 3: Generate Custom SRS**

```bash
python main_orchestrator.py --mode srs \
    --results_file processed_results.json \
    --project_title "Financial Trading Platform" \
    --project_author "Development Team" \
    --project_version "2.0"
```

## üìã Configuration Options

### **Model Configuration**
```python
config = Config(
    whisper_model_size="small",        # tiny, base, small, medium, large
    flan_model_name="google/flan-t5-base",
    spacy_model_name="en_core_web_sm",
    max_workers=4,                     # Parallel processing threads
    batch_size=10,                     # Items per batch
    max_audio_duration=300             # Max audio length (seconds)
)
```

### **Directory Configuration**
```python
config = Config(
    input_dir="data/input",
    output_dir="data/output", 
    temp_dir="data/temp",
    models_dir="models"
)
```

## üõ†Ô∏è Advanced Features

### **Custom Ambiguity Patterns**
```python
# Add custom ambiguity detection patterns
ambiguity_patterns = {
    'financial_terms': ['volatile', 'liquid', 'stable', 'risky'],
    'technical_terms': ['scalable', 'robust', 'efficient', 'optimized']
}
```

### **Custom SRS Templates**
```python
# Customize SRS generation
srs_template = {
    "introduction": {
        "purpose": "Custom purpose section",
        "scope": "Custom scope section"
    }
}
```

### **Data Export Options**
```bash
# Export to different formats
python main_orchestrator.py --mode export --export_format csv
python main_orchestrator.py --mode export --export_format json
```

## üìä Monitoring and Statistics

### **System Statistics**
```bash
python main_orchestrator.py --mode stats
```

**Output:**
```json
{
  "total_records": 150,
  "successful": 145,
  "failed": 5,
  "success_rate": 0.967,
  "total_ambiguities": 23,
  "avg_ambiguities_per_requirement": 0.16
}
```

### **Processing History**
- Track all processing attempts
- Monitor success/failure rates
- Identify problematic inputs
- Performance metrics

## üîß Troubleshooting

### **Common Issues**

**1. Memory Issues**
```bash
# Reduce batch size
python main_orchestrator.py --mode batch --config_file low_memory_config.json
```

**2. Audio Processing Errors**
```bash
# Check FFmpeg installation
ffmpeg -version

# Install FFmpeg (Windows)
# Download from https://ffmpeg.org/download.html
```

**3. Model Download Issues**
```bash
# Clear model cache and re-download
rm -rf ~/.cache/huggingface/
python main_orchestrator.py --mode single --input_text "test"
```

### **Performance Optimization**

**1. CPU Optimization**
- Use smaller models for faster processing
- Adjust `max_workers` based on CPU cores
- Enable CPU-specific optimizations

**2. Memory Optimization**
- Reduce `batch_size` for large datasets
- Use model quantization
- Clear unused models from memory

**3. Storage Optimization**
- Use Parquet format for large datasets
- Enable data compression
- Regular cleanup of temporary files

## üìö API Reference

### **RequirementsProcessor**
```python
processor = RequirementsProcessor(config)
result = processor.process_single_requirement(input_data)
```

### **BatchProcessor**
```python
batch_processor = BatchProcessor(config)
results = batch_processor.process_directory("data/input")
```

### **SRSGenerator**
```python
generator = SRSGenerator()
srs = generator.generate_srs(requirements_data)
```

### **DataManager**
```python
data_manager = DataManager()
data_manager.add_record(record)
records = data_manager.list_records(status='completed')
```

## üöÄ Next Steps

### **For Production Deployment**
1. **Containerization**: Docker setup for deployment
2. **API Development**: REST API for web integration
3. **Database Scaling**: PostgreSQL/MySQL for large datasets
4. **Monitoring**: Prometheus/Grafana integration
5. **CI/CD**: Automated testing and deployment

### **For Research and Development**
1. **Model Fine-tuning**: Domain-specific model training
2. **Advanced NLP**: Custom ambiguity detection models
3. **Multi-language Support**: International requirements
4. **Integration**: Jira, Confluence, GitHub integration

## üìû Support

For issues, questions, or contributions:
- Check the logs in `requirements_system.log`
- Review the database in `requirements.db`
- Examine the configuration in your config file

## üìÑ License

This project is part of your FYP (Final Year Project) for requirements engineering research and development.

---

**System Version**: 1.0  
**Last Updated**: October 2024  
**Compatibility**: Python 3.8+, Windows/Linux/macOS
